<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <title>Labtech: Concurrency and caching in Python for busy scientists</title>

    <link rel="stylesheet" href="dist/reset.css">
    <link rel="stylesheet" href="dist/reveal.css">
    <link rel="stylesheet" href="dist/theme/black.css">

    <!-- Theme used for syntax highlighted code -->
    <link rel="stylesheet" href="plugin/highlight/monokai.css">

    <style>
     @font-face {
         font-family: 'Ubuntu';
         font-style: normal;
         font-weight: 300;
         src: url(fonts/ubuntu/Ubuntu-Light.ttf);
     }
     @font-face {
         font-family: 'Ubuntu';
         font-style: italic;
         font-weight: 300;
         src: url(fonts/ubuntu/Ubuntu-LightItalic.ttf);
     }
     @font-face {
         font-family: 'Ubuntu';
         font-style: normal;
         font-weight: 400;
         src: url(fonts/ubuntu/Ubuntu-Regular.ttf);
     }
     @font-face {
         font-family: 'Ubuntu';
         font-style: italic;
         font-weight: 400;
         src: url(fonts/ubuntu/Ubuntu-Italic.ttf);
     }
     @font-face {
         font-family: 'Ubuntu';
         font-style: normal;
         font-weight: 500;
         src: url(fonts/ubuntu/Ubuntu-Medium.ttf);
     }
     @font-face {
         font-family: 'Ubuntu';
         font-style: italic;
         font-weight: 500;
         src: url(fonts/ubuntu/Ubuntu-MediumItalic.ttf);
     }
     @font-face {
         font-family: 'Ubuntu';
         font-style: normal;
         font-weight: 700;
         src: url(fonts/ubuntu/Ubuntu-Bold.ttf);
     }
     @font-face {
         font-family: 'Ubuntu';
         font-style: italic;
         font-weight: 700;
         src: url(fonts/ubuntu/Ubuntu-BoldItalic.ttf);
     }
     @font-face {
         font-family: 'Ubuntu Mono';
         font-style: normal;
         font-weight: 400;
         src: url(fonts/ubuntu_mono/UbuntuMono-Regular.ttf);
     }
     @font-face {
         font-family: 'Ubuntu Mono';
         font-style: italic;
         font-weight: 400;
         src: url(fonts/ubuntu_mono/UbuntuMono-Italic.ttf);
     }
     @font-face {
         font-family: 'Ubuntu Mono';
         font-style: normal;
         font-weight: 700;
         src: url(fonts/ubuntu_mono/UbuntuMono-Bold.ttf);
     }
     @font-face {
         font-family: 'Ubuntu Mono';
         font-style: italic;
         font-weight: 700;
         src: url(fonts/ubuntu_mono/UbuntuMono-BoldItalic.ttf);
     }

     :root {
         --r-background-color: #21125E;
         --r-link-color: #4618f1;
         --r-main-font: 'Ubuntu', sans-serif;
         --r-heading-font: 'Ubuntu', sans-serif;
     }

     .reveal pre code.hljs {
         background: #3C3752;
         padding: 10px;
         border-radius: 5px;
     }
     .hljs-meta {
         color: #AC99F2;
     }

     .reveal h1, .reveal h2, .reveal h3, .reveal h4, .reveal h5, .reveal h6 {
         text-transform: none;
     }

     .tasks {
         margin: 40px 0;
         position: relative;
         font-family: 'Ubuntu Mono', monospace, sans-serif;
     }

     .tasks .task-line {
         margin: 30px 0;
         display: flex;
         gap: 50px;
         position: relative;
     }

     .tasks .task {
         box-sizing: border-box;
         height: 60px;
         width: 100%;
         position: relative;
         background: #D1CEB0;
         border: 7px solid #8F8F8F;
         border-radius: 7px;
     }

     .tasks .task .task-label {
         position: relative;
         z-index: 1;
         line-height: 46px;
         color: black;
         font-weight: bold;
     }

     .tasks .task .task-progress {
         position: absolute;
         top: 0;
         left: 0;
         width: 0%;
         height: 100%;
         background: #FFE500;
     }

     .tasks .task.cached.fragment {
         visibility: visible;
         opacity: 100;
     }

     .tasks .task.cached.fragment.visible {
         background: #00FF66;
     }

     section.present > .tasks .task .task-progress.visible {
         animation-duration: 5s;
         /* animation-iteration-count: infinite; */
         animation-fill-mode: forwards;
         animation-timing-function: linear;
     }

     .arrow {
         position: absolute;
         z-index: -1;
     }
     .arrow .arrow-shaft {
         width: 100%;
         height: 5px;
         background: white;
     }
     .arrow .arrow-head {
         position: absolute;
         right: -7px;
         top: -7.5px;
         width: 0;
         height: 0;
         border-top: 10px solid transparent;
         border-bottom: 10px solid transparent;
         border-left: 10px solid white;
     }

     .reveal .highlight.fragment {
         color: var(--r-main-color);
         visibility: visible;
         opacity: 100;
     }

     .reveal .highlight, .reveal .highlight.fragment.visible {
         color: #FFE500;
     }

     .reveal video {
         border: 7px solid #8F8F8F;
         border-radius: 5px;
     }

     ::-webkit-scrollbar {
         width: 16px;
     }
     ::-webkit-scrollbar-track {
         background: none;
     }
     ::-webkit-scrollbar-thumb {
         background: #4E486B;
         border-radius: 8px;
     }

    </style>

  </head>
  <body>
    <div class="reveal">
      <div class="slides">
        <section data-markdown>
          <textarea data-template>
<h1 class="highlight">labtech</h1>

<div style="width: 260px; height: 260px; margin: 20px auto; background: white; border-radius: 50%; display: flex; align-items: center; justify-content: center;">
  <img src="images/fifo.svg" style="width: 85%; margin: 0;">
</div>

<h2 style="font-size: 1.3em;"><span class="highlight">Concurrency</span> and <span class="highlight">caching</span> in Python for <span class="highlight">busy scientists</span></h2>

## Ben Denham - Software Engineer & Data Scientist  <!-- .element style="font-size: 0.8em;" -->

<aside class="notes">

  * Hi everyone, I'm Ben
  * I'm going to share with you about labtech
  * A tool I've developed to scratch my own itch for managing lots of computational experiments
  * and I think you'll find it useful as well!

</aside>

          </textarea>
        </section>

        <section data-markdown>
          <textarea data-template>
## What is <span class="highlight">labtech</span> ?

<div class="fragment">

A <span class="highlight fragment">friendly</span> Python library for <span class="highlight fragment">efficiently</span> running and managing computational <span class="highlight fragment">experiments</span>

</div>

<aside class="notes">

  * So what is labtech?
  * At a high level: *read verbatim*
  * Who - it's friendly - for scientists and other Python users who aren't primarily software engineers
  * Why - work more efficiently
  * What - computational experiments

</aside>
          </textarea>
        </section>

        <section data-markdown>
          <textarea data-template>
### What counts as an <span class="highlight">*Experiment*</span> ?

  <ul>
    <li class="fragment">
      <strong>Typically:</strong>
      <ul>
        <li>Running an expensive simulation</li>
        <li>Training a machine learning model</li>
      </ul>
    </li>
    <li class="fragment">
      <strong>Technically:</strong>
      <ul>
        <li>
          Any <span class="highlight">task</span> run with <span class="highlight">many configurations</span>,
          <br>often made up of <span class="highlight">multiple steps</span>
        </li>
        <li class="fragment">
          E.g. A web-scraper run on many webpages
        </li>
      </ul>
    </li>
  </ul>

<aside class="notes">

  * Some typical examples would be... (from slide)
  * But technically, it could be any task that... (from slide)
  * For example, even... (webscraping from slide)

</aside>

          </textarea>
        </section>

        <section data-markdown>
          <textarea data-template>
### The Essence of an Experiment: <span class="highlight">Interactivity</span>

* Closely monitoring execution
* Adding/modifying experiments based on results
* You need to <span class="highlight">iterate as fast as possible!</span>

<aside class="notes">

  * But the essence of experiments that labtech helps most with is
    summed up with one word: Interactivity
  * You don't know whether the ideas you're trying will work
  * ...so you keep a close eye while they're running
  * You're going to change direction based on the results
  * ..modifying experiment configurations or coming up with new ideas
  * and you want to move fast
  * ...reducing the time between asking a question and getting an answer

</aside>

          </textarea>
        </section>

        <style>
         table.bar-chart {
             width: 100%;
             font-size: 0.55em;
         }
         table.bar-chart td {
             width: 30%;
             text-align: center;
         }
         table.bar-chart .bar-container {
             height: 300px;
             vertical-align: bottom;
             position: relative;
         }
         table.bar-chart .bar-container .bar {
             width: 100px;
             background: var(--r-link-color);
             position: absolute;
             bottom: 0;
             left: 50%;
             transform: translate(-50%, 0);
         }

         table.bar-chart .bar-container .bar.height-fragment.fragment {
             opacity: 1;
             visibility: visible;
             height: 100%;
             transition: all 0.5s linear;
         }
         table.bar-chart .bar-container .bar.height-fragment.fragment.height-fragment-a.visible {
             height: 84% !important;
             z-index: -1;
         }
         table.bar-chart .bar-container .bar.height-fragment.fragment.height-fragment-b.visible {
             height: 18% !important;
         }
         table.bar-chart .bar-container .bar.height-fragment.fragment.height-fragment-c.visible {
             height: 6% !important;
         }

         table.bar-chart .bar-container .bar.color-fragment.fragment {
             opacity: 1;
             visibility: visible;
             transition: all 0.5s linear;
         }
         table.bar-chart .bar-container .bar.color-fragment.fragment.color-fragment-a.visible {
             /* background: #285864 !important; */
         }

         table.bar-chart img.emoji-icon {
             margin: 0;
             width: 100px;
         }
        </style>
        <section data-markdown>
          <textarea data-template>
          <h3>Experiment Iterations</h3>
          <table class="bar-chart">
            <tr>
              <td class="bar-container fragment" data-fragment-index="1">
                <div class="fragment bar height-fragment height-fragment-a" style="height: 0%; display: flex; justify-content: center;" data-fragment-index="4">
                  <img src="images/fifo.svg" style="margin: 0;">
                </div>
                <div class="bar fragment color-fragment color-fragment-a" style="height: 12%; background: #37FA71;" data-fragment-index="4"></div>
              </td>
              <td class="bar-container fragment" data-fragment-index="2">
                <div class="bar" style="height: 42%; background: #EBC334; opacity: 0.3;"></div>
                <div class="fragment bar height-fragment height-fragment-b" style="height: 42%; background: #EBC334;" data-fragment-index="4"></div>
              </td>
              <td class="bar-container fragment" data-fragment-index="3">
                <div class="bar" style="height: 66%; background: #F5363F; opacity: 0.3;"></div>
                <div class="fragment bar height-fragment height-fragment-c" style="height: 66%; background: #F5363F;" data-fragment-index="4"></div>
              </td>
            </tr>
            <tr>
              <td class="fragment" data-fragment-index="1"><img class="emoji-icon" src="images/emoji_cool.svg"><br>0 &ndash; 5 mins</td>
              <td class="fragment" data-fragment-index="2"><img class="emoji-icon" src="images/emoji_annoyed.svg"><br>5 mins &ndash; 1 hour</td>
              <td class="fragment" data-fragment-index="3"><img class="emoji-icon" src="images/emoji_sleep.svg"><br>1 hour &ndash; 1+ days</td>
            </tr>
          </table>

<aside class="notes">

  * Because while some of your experiment ideas will only take a few minutes to test
  * ...others might take more time - long enough you risk losing your train of thought
  * ...up to an hour particularly annoys me, because it isn't even long enough to be worth switching context to another task
  * ...but then there are experiments where you might just have to wait up to a day or more to see results
  * Labtech's job is to make it faster to test more of your ideas by both
  * ...reducing unnecessary computation
  * ...and helping you better manage your experiments
    * Aside: E.g. know what you've already run, know what's taking too long, extend experiment code

</aside>

          </textarea>
        </section>

        <section data-markdown>
          <textarea data-template>
## Overview

1. Applying labtech to speed-up ML experiments
2. More labtech features for faster experiments
3. How labtech compares to similar tools

<aside class="notes">

  * So over the rest of this talk, we're going to look at...

</aside>

          </textarea>
        </section>

        <section>

          <style>
           /* See: https://css-tricks.com/snippets/css/css-triangle/ */
           .experiment-steps {
               display: flex;
               margin: 10px 0;
           }
           .experiment-steps .experiment-step {
               height: 60px;
               width: 230px;
               line-height: 60px;
               background: url(images/chevron.svg);
               background-size: 100% 100%;
               color: black;
               font-weight: bold;
               font-size: 0.9em;
               padding-left: 15px;
           }
           .experiment-steps .experiment-step.current-fragment {
               background-image: url(images/chevron-active.svg);
           }

           @keyframes task-progress-1 {
               0% { width: 0%; }
               80% { width: 100%; }
               100% { width: 100%; }
           }
          </style>

          <section data-markdown>
            <textarea data-template>
#### Example: Machine Learning Experiments

<div class="experiment-steps">
  <div class="experiment-step fragment" data-fragment-index="1">Load</div>
  <div class="experiment-step fragment" data-fragment-index="2">Prepare</div>
  <div class="experiment-step fragment" data-fragment-index="3">Train</div>
  <div class="experiment-step fragment" data-fragment-index="4">Evaluate</div>
</div>

<div style="font-size: 0.72em;">

<pre><code data-trim data-noescape class="python language-python" data-fragment-index="1" data-line-numbers="|2-4|6-9|1,11-14|16-17|19">
def run_experiment(leaf_max: int):
    # Load train and test datasets
    txt_train = fetch_20newsgroups(subset='train')
    txt_test = fetch_20newsgroups(subset='test')

    # Prepare "bag-of-words" (BoW) representation of text
    vectorizer = CountVectorizer(binary=True)
    bow_train = vectorizer.fit_transform(txt_train.data)
    bow_test = vectorizer.transform(txt_test.data)

    # Train classifier to predict topic labels from BoW
    classifier = RandomForestClassifier(max_leaf_nodes=leaf_max, random_state=1)
    classifier.fit(bow_train, txt_train.target)
    target_pred = classifier.predict(bow_test)

    # Evaluate classifier accuracy
    return accuracy_score(txt_test.target, target_pred)

run_experiment(leaf_max=50)
</code></pre>

</div>

<div class="tasks fragment" style="margin: 10px 0;" data-fragment-index="5">
  <div class="task-line">
    <div class="task">
      <div class="task-progress fragment" data-fragment-index="11" data-animation-name="task-progress-1"></div>
      <div class="task-label">run_experiment(leaf_max=50)</div>
    </div>
  </div>
</div>

<aside class="notes">

  * So let's look at how labtech can speed up some machine learning experiments
  * Here is our experiment code without labtech
  * The details aren't important
  * ... but at a high-level, during each experiment, we:
    * load a dataset of text from online forum
    * prepare a numerical bag-of-words representation of the text
    * then train a classifier to assign a topic label to a forum message
      * the experiment also takes a `leaf_max` parameter that affects how the classifier is trained
    * and finally evaluate the accuracy of the classifier
  * The key point to understand: each experiment takes a while to run

</aside>

            </textarea>
          </section>

        </section>

        <section>

          <style>
           .tasks-2 .task .task-progress {
               animation-duration: 13s !important;
           }
           @keyframes task-progress-2a {
               0% { width: 0%; }
               30% { width: 100%; }
               100% { width: 100%; }
           }
           @keyframes task-progress-2b {
               0% { width: 0%; }
               30% { width: 0%; }
               60% { width: 100%; }
               100% { width: 100%; }
           }
           @keyframes task-progress-2c {
               0% { width: 0%; }
               60% { width: 0%; }
               90% { width: 100%; }
               100% { width: 100%; }
           }
          </style>

          <section data-markdown>
            <textarea data-template>
### Slow-Down #1: Parameter Permutations

```python
for leaf_max in [10, 50, 90]:
    run_experiment(leaf_max=leaf_max)
```


<div class="tasks tasks-2">
  <div class="task-line">
    <div class="task">
      <div class="task-progress fragment" data-fragment-index="1" data-animation-name="task-progress-2a"></div>
      <div class="task-label">run_experiment(leaf_max=10)</div>
    </div>
  </div>
  <div class="task-line">
    <div class="task">
      <div class="task-progress fragment" data-fragment-index="1" data-animation-name="task-progress-2b"></div>
      <div class="task-label">run_experiment(leaf_max=50)</div>
    </div>
  </div>
  <div class="task-line">
    <div class="task">
      <div class="task-progress fragment" data-fragment-index="1" data-animation-name="task-progress-2c"></div>
      <div class="task-label">run_experiment(leaf_max=90)</div>
    </div>
  </div>
</div>

<aside class="notes">

  * While running experiment permutations with varied parameters, we'll very quickly notice our first speed impediment
  * Running lots of experiments one-after-another is going to take a while!

</aside>

            </textarea>
          </section>

          <style>
           @keyframes task-progress-3 {
               0% { width: 0%; }
               80% { width: 100%; }
               100% { width: 100%; }
           }
          </style>

          <section data-markdown>
            <textarea data-template>
### Speed-Up #1: Concurrency!

<div class="tasks">
  <div class="task-line">
    <div class="task">
      <div class="task-progress fragment" data-fragment-index="1" data-animation-name="task-progress-3"></div>
      <div class="task-label">Experiment(leaf_max=10)</div>
    </div>
  </div>
  <div class="task-line">
    <div class="task">
      <div class="task-progress fragment" data-fragment-index="1" data-animation-name="task-progress-3"></div>
      <div class="task-label">Experiment(leaf_max=50)</div>
    </div>
  </div>
  <div class="task-line">
    <div class="task">
      <div class="task-progress fragment" data-fragment-index="1" data-animation-name="task-progress-3"></div>
      <div class="task-label">Experiment(leaf_max=90)</div>
    </div>
  </div>
</div>

<aside class="notes">

  * Labtech makes it easy to run as many experiments at the same time as our computer can handle

</aside>

            </textarea>
          </section>

          <section data-markdown>
            <textarea data-template>
### Parallel tasks with labtech

<div style="font-size: 0.9em;">

```python [|3-8|10-13|15-16]
import labtech as lt

@lt.task
class Experiment:
    leaf_max: int

    def run(self):
        return run_experiment(leaf_max=self.leaf_max)

experiments = [
    Experiment(leaf_max=leaf_max)
    for leaf_max in [10, 50, 90]
]

lab = lt.Lab(storage=None, max_workers=3)
results = lab.run_tasks(experiments)
```

</div>

<aside class="notes">

  * And here's what that looks like
  * We define a Task class for our experiment that just needs to run our original experiment code
    * Similar to a dataclass, we declare any parameters of the experiment as attributes
  * Then we create an instance of our Experiment Task for each permutation that we want to run
  * Then we instruct labtech to run the experiment tasks
  * Setting `max_workers` tells labtech to run up to 3 tasks at a time
    * ...perfect for a typical 4-core CPU

</aside>


            </textarea>
          </section>

          <section data-markdown>
            <textarea data-template>
            <video data-autoplay loop src="images/labtech_concurrency_jupyter.webm"></video>
            <video class="fragment" data-autoplay loop src="images/labtech_concurrency_console.webm"></video>
            </textarea>

<aside class="notes">

  * When we run these experiments:
    * labtech shows a progress bar (courtesy of the tqdm library)
    * And shows each running task along with the CPU and RAM it's using
    * Tasks can also log messages to be displayed
  * This works in Jupyter notebooks, as well as at the command line

</aside>

          </section>

        </section>

        <section>

          <style>
           .tasks-3 .task-label {
               text-align: left;
               padding-left: 30px;
           }
          </style>
          <section data-markdown>
            <textarea data-template>
### Slow-Down #2: Redundancy in Tasks

<div class="tasks tasks-3" style="font-size: 0.9em;">
  <div class="task-line">
    <div class="task">
      <div class="task-progress fragment" data-fragment-index="1" data-animation-name="task-progress-3"></div>
      <div class="task-label">Load → Prepare → Train (leaf_max=10) → Evaluate</div>
    </div>
  </div>
  <div class="task-line">
    <div class="task">
      <div class="task-progress fragment" data-fragment-index="1" data-animation-name="task-progress-3"></div>
      <div class="task-label">Load → Prepare → Train (leaf_max=50) → Evaluate</div>
    </div>
  </div>
  <div class="task-line">
    <div class="task">
      <div class="task-progress fragment" data-fragment-index="1" data-animation-name="task-progress-3"></div>
      <div class="task-label">Load → Prepare → Train (leaf_max=90) → Evaluate</div>
    </div>
  </div>
</div>

<aside class="notes">

  * So now that you have your experiments running in parallel
  * ...the next slow-down you might notice is how some computation gets repeated across experiments
  * ...such as in these Load and Prepare steps before the parameter variations affect the training and evaluation

</aside>

            </textarea>
          </section>

          <style>
           @keyframes task-progress-4a {
               0% { width: 0%; }
               40% { width: 100%; }
               100% { width: 100%; }
           }
           @keyframes task-progress-4b {
               0% { width: 0%; }
               40% { width: 0%; }
               90% { width: 100%; }
               100% { width: 100%; }
           }
          </style>

          <section data-markdown>
            <textarea data-template>
### Speed-Up #2: Share Dependencies

<div class="tasks" style="font-size: 0.9em;">
  <div class="task-line">
    <div class="arrow" style="top: 75px; left: 237px; width: 65px; transform: rotate(0.375turn);"><div class="arrow-shaft"></div><div class="arrow-head"></div></div>
    <div style="width: 25%;"></div>
    <div class="task" style="width: 65%;">
      <div class="task-progress fragment" data-fragment-index="1" data-animation-name="task-progress-4b"></div>
      <div class="task-label">ClassificationTask(leaf_max=10)</div>
    </div>
  </div>
  <div class="task-line">
    <div class="arrow" style="top: 27.5px; left: 248px; width: 65px; transform: rotate(0.5turn);"><div class="arrow-shaft"></div><div class="arrow-head"></div></div>
    <div class="task" style="width: 25%;">
      <div class="task-progress fragment" data-fragment-index="1" data-animation-name="task-progress-4a"></div>
      <div class="task-label">BowTask()</div>
    </div>
    <div class="task" style="width: 65%;">
      <div class="task-progress fragment" data-fragment-index="1" data-animation-name="task-progress-4b"></div>
      <div class="task-label">ClassificationTask(leaf_max=50)</div>
    </div>
  </div>
  <div class="task-line">
    <div class="arrow" style="top: -20px; left: 237px; width: 65px; transform: rotate(0.625turn);"><div class="arrow-shaft"></div><div class="arrow-head"></div></div>
    <div style="width: 25%;"></div>
    <div class="task" style="width: 65%;">
      <div class="task-progress fragment" data-fragment-index="1" data-animation-name="task-progress-4b"></div>
      <div class="task-label">ClassificationTask(leaf_max=90)</div>
    </div>
  </div>
</div>

<aside class="notes">

  * What we'd like to have is a single task to prepare the bag-of-words data once
  * ...and have classification task permutations share the result

</aside>

            </textarea>
          </section>

          <section data-markdown>
            <textarea data-template>

<div style="font-size: 0.74em;">

### Defining Task Types with Dependencies

```python [|10,14]
@lt.task
class BowTask:

    def run(self):
        ...
        return (bow_train, bow_test, target_train, target_test)

@lt.task
class ClassificationTask:
    data_task: BowTask
    leaf_max: int

    def run(self):
        bow_train, bow_test, target_train, target_test = self.data_task.result
        ...
        return accuracy_score(...)
```

</div>

<aside class="notes">

  * Here's what that looks like in labtech
  * We define two task types
  * And we make the first task a dependency of the send task by declaring it as a parameter
  * We can then access the first task's result when the second task is running

</aside>

            </textarea>
          </section>

          <section data-markdown>
            <textarea data-template>
### Running Tasks with Dependencies

```python [|3]
experiments = [
    ClassificationTask(
        data_task=BowTask(),
        leaf_max=leaf_max,
    )
    for leaf_max in [10, 50, 90]
]
lab = lt.Lab(storage=None)
results = lab.run_tasks(experiments)
```

<aside class="notes">

  * We declare our experiment permutations as before
  * ...except this time, we create a bag-of-words task and pass it through as a parameter
  * We actually create multiple bag-of-words tasks in this for-loop,
  * ...but labtech knows they are the same because they have the same parameters (or none in this case)

</aside>

            </textarea>
          </section>

          <section data-markdown>
            <textarea data-template>
            <video data-autoplay loop src="images/labtech_dependencies_jupyter.webm"></video>

<aside class="notes">

  * And when we run the experiments, we get a progress bar for each type of task

</aside>
            </textarea>
          </section>

        </section>

        <section>

          <section data-markdown>
            <textarea data-template>
### Slow-Down #3: Re-running Tasks

* Forgetting to save final results <!-- .element class="fragment" -->
* Forgetting what parameters were used <!-- .element class="fragment" -->
* Not saving intermediate results <!-- .element class="fragment" -->

<aside class="notes">

  * Now that we have tasks sharing dependencies and running in parallel,
  * ...the final slow-down we'll look at is all the time you can spend re-running tasks you've run before
  * This might happen for various reasons...
    * Forgetting to save the results from an experiment you ran
    * Even if you save the result, you might forget to record the parameters you used
    * And finally, sometimes you want to change a later step in an experiment,
      ...but then you have to re-run the whole experiment because you didn't save intermediate results after earlier steps

</aside>

            </textarea>
          </section>

          <style>
           @keyframes task-progress-5a {
               0% { width: 0%; }
               40% { width: 100%; }
               100% { width: 100%; }
           }
           @keyframes task-progress-5b {
               0% { width: 0%; }
               50% { width: 100%; }
               100% { width: 100%; }
           }
           @keyframes task-progress-5c {
               0% { width: 0%; }
               40% { width: 0%; }
               90% { width: 100%; }
               100% { width: 100%; }
           }
          </style>

          <section data-markdown>
            <textarea data-template>
### Speed-Up #3: Caching Task Results

<div class="tasks" style="font-size: 0.75em;">
  <div class="task-line">
    <div class="arrow" style="top: 75px; left: 284px; width: 65px; transform: rotate(0.375turn);"><div class="arrow-shaft"></div><div class="arrow-head"></div></div>
    <div style="width: 30%;"></div>
    <div class="task fragment cached" data-fragment-index="0" style="width: 60%;">
      <div class="task-label">ClassificationTask(leaf_max=10)</div>
    </div>
  </div>
  <div class="task-line">
    <div class="arrow" style="top: 27.5px; left: 295px; width: 65px; transform: rotate(0.5turn);"><div class="arrow-shaft"></div><div class="arrow-head"></div></div>
    <div class="task fragment cached" data-fragment-index="0" style="width: 30%;">
      <div class="task-label">BowTask()</div>
    </div>
    <div class="task fragment cached" data-fragment-index="0" style="width: 60%;">
      <div class="task-label">ClassificationTask(leaf_max=50)</div>
    </div>
  </div>
  <div class="task-line">
    <div class="arrow" style="top: -20px; left: 284px; width: 65px; transform: rotate(0.625turn);"><div class="arrow-shaft"></div><div class="arrow-head"></div></div>
    <div style="width: 30%;"></div>
    <div class="task fragment cached" data-fragment-index="0" style="width: 60%;">
      <div class="task-label">ClassificationTask(leaf_max=90)</div>
    </div>
  </div>
  <div class="task-line">
    <div class="arrow" style="top: -49px; left: 243px; width: 150px; transform: rotate(0.68turn);"><div class="arrow-shaft"></div><div class="arrow-head"></div></div>
    <div style="width: 30%;"></div>
    <div class="task" style="width: 60%;">
      <div class="task-progress fragment" data-fragment-index="1" data-animation-name="task-progress-5b"></div>
      <div class="task-label">ClassificationTask(leaf_max=1000)</div>
    </div>
  </div>
  <div class="task-line">
    <div class="arrow" style="top: 27.5px; left: 295px; width: 65px; transform: rotate(0.5turn);"><div class="arrow-shaft"></div><div class="arrow-head"></div></div>
    <div class="task" style="width: 30%;">
      <div class="task-progress fragment" data-fragment-index="1" data-animation-name="task-progress-5a"></div>
      <div class="task-label">EmbeddingsTask()</div>
    </div>
    <div class="task" style="width: 60%;">
      <div class="task-progress fragment" data-fragment-index="1" data-animation-name="task-progress-5c"></div>
      <div class="task-label">ClassificationTask(leaf_max=50)</div>
    </div>
  </div>
  <div class="task-line">
    <div class="arrow" style="top: -20px; left: 284px; width: 65px; transform: rotate(0.625turn);"><div class="arrow-shaft"></div><div class="arrow-head"></div></div>
    <div style="width: 30%;"></div>
    <div class="task" style="width: 60%;">
      <div class="task-progress fragment" data-fragment-index="1" data-animation-name="task-progress-5c"></div>
      <div class="task-label" style="position: relative; top: -8px;">...</div>
    </div>
  </div>
</div>

<aside class="notes">

  * Labtech solves this problem by *always* saving the results of tasks along with the parameters used
  * So when we construct a bunch of tasks and run them
  * ...labtech will load the results of any tasks it's run before from its cache
  * ...and only execute the new tasks
  * For example, here we have a new Embeddings Task to prepare a different numeric representation of our text data,
  * ...and that can run at the same time as any Classification task that still depends on the cached bag-of-words task

</aside>

            </textarea>
          </section>

          <section data-markdown>
            <textarea data-template>
## Result caching in labtech

```python
lab = lt.Lab(storage='task_results/')
```

<div class="fragment">

```python
# Find cached tasks
tasks = lab.cached_tasks([BowTask, ClassificationTask])
```

</div>

<div class="fragment">

```python
# Load their results
lab.run_tasks(tasks)
```

</div>

<div class="fragment">

```python
# Uncache tasks
lab.uncache_tasks(tasks)
```

</div>

<aside class="notes">

  * This is as simple as telling labtech what directory to store its cache in
  * We can even ask labtech to fully re-construct Task objects for any results it has cached
  * And we load their cached results by simply asking labtech to run them
  * Finally, we can also ask labtech to uncache specific results when necessary
  * ...such as if we've changed the code that a task runs

</aside>

            </textarea>
          </section>

        </section>

        <section>

          <section data-markdown>
            <textarea data-template>
### Continuing our Experimentation

<div class="fragment" data-fragment-index="3">

```python
from labtech.diagram import display_task_diagram
display_task_diagram(experiments)
```

</div>

<div class="r-stack" style="width: 80%; margin: auto;">
  <img src="images/task-diagram-1.svg">
  <img src="images/task-diagram-2.svg" class="fragment" data-fragment-index="1">
  <img src="images/task-diagram-3.svg" class="fragment" data-fragment-index="2">
</div>

<aside class="notes">

  * We could continue modifying our experiments over time to handle more complexity
    * We could make the type of classifier itself a task dependency of our classification task
    * And we could move classifier evaluation into a separate task, allowing us to cache the classifier outputs themselves
    * ...so that we can later run any kind of evaluation we come up with
  * By the way, Labtech can generate a diagram of dependencies like this for any set of tasks

</aside>

            </textarea>
          </section>

          <section data-markdown>
            <textarea data-template>
### Manage <span class="highlight">hundreds of tasks</span> with a <span class="highlight">few lines of code</span>

```python [1-4|6-19|21-30]
data_tasks = [
    BowTask(),
    EmbeddingsTask(),
]

classifier_tasks = [
    *[
        RandomForestClassifierTask(
            leaf_max=leaf_max,
            tree_count=tree_count,
        )
        for leaf_max in [10, 20, 40, 80, 160]
        for tree_count in range(10, 110, 10)
    ],
    *[
        NaiveBayesTask(alpha=alpha)
        for alpha in [0.1, 0.5, 1.0, 1.5, 2.0]
    ],
]

experiments = [
    EvaluationTask(
        classification_task=ClassificationTask(
            data_task=data_task,
            classifier_task=classifier_task,
        ),
    )
    for data_task in data_tasks
    for classifier_task in classifier_tasks
]
```

<aside class="notes">

  * Even as our experiment permutations grow, labtech keeps the configuration easy to manage
  * Here we define a list of tasks that prepare our dataset in different ways
  * Then we define a list with multiple types of classifiers with varied parameters
  * And finally we define each experiment as:
    * ...an evaluation task
    * ...run for a classification task
    * ...with a given dataset and classifier

</aside>

            </textarea>
          </section>

          <style>
           .reveal table.pricing-table td {
               vertical-align: top;
               text-align: center;
           }
           .reveal table.pricing-table td:first-child {
               vertical-align: middle;
               border-right: 1px solid white;
           }
           .reveal table.pricing-table td img {
               margin: 0;
               height: 100px;
           }
          </style>
          <section data-markdown>
            <textarea data-template>
## Scaling Up: To the Cloud!

<p style="font-size: 0.5em;">(Disclaimer: Based on USD Spot Pricing in an East US Region - don't quote me on these prices!)</p>

<table class="pricing-table">
  <tr class="fragment">
    <td>Azure</td>
    <td colspan="2"><img src="images/azure-spot-instance.png"></td>
  </tr>
  <tr class="fragment">
    <td>AWS</td>
    <td><img src="images/aws-spot-size.png"></td>
    <td><img src="images/aws-spot-pricing.png"></td>
  </tr>
  <tr class="fragment">
    <td>Google</td>
    <td><img src="images/google-spot-size.png"></td>
    <td><img src="images/google-spot-pricing.png"><div style="font-size: 0.6em;">(~$1.8356/hour)</div></td>
  </tr>
</table>

<aside class="notes">

  * Now to run your hundreds of experiments as fast as possible, you might think you need to pay for a big cluster of machines
  * However, you can get pretty far with a single big virtual machine in the cloud:
    * How about enough cores to run 96 tasks at the same time?
    * How about 192 tasks?
    * Or even 360 tasks?
    * All for dollars an hour or less.
  * Now we're looking at spot instances, which means your machine might be shutdown with no notice
  * ...but that's not a big problem with labtech caching all your intermediate results!
  * Just restart the machine and let labtech pick up from where it left off

</aside>

            </textarea>
          </section>

          <section data-markdown>
            <textarea data-template>
## More Conveniences

* <!-- .element class="fragment" -->Always <span class="highlight">records task execution time</span>
* <!-- .element class="fragment" -->Tasks can <span class="highlight">continue even when one fails</span>
* <!-- .element class="fragment" --><span class="highlight">Conserve RAM</span> by sharing data between tasks (Linux-only for now)

<aside class="notes">

* I've also packed labtech with a bunch of other conveniences I found myself wanting
* It always saves how long a task took to run
* It can continue running other tasks even when one fails
  * (useful if you're going to run it overnight)
* And it can conserve RAM on Linux by sharing memory between tasks

</aside>

            </textarea>
          </section>

          <style>
           .side-by-side-code {
               display: flex;
               font-size:
           }
           .side-by-side-code > div {
               width: 48%;
           }
          </style>
          <section data-markdown>
            <textarea data-template>
## Designed for Customisation

<div class="side-by-side-code">

<div class="fragment">

```python
class CloudStorage(Storage):
    ...

lab = lt.Lab(
  storage=CloudStorage(...),
)
```

</div>

<div class="fragment">

```python
class CsvCache(BaseCache):
    ...

@lt.task(cache=CsvCache())
class TableTask:
    ...
```

</div>

</div>

<aside class="notes">

  * Finally, labtech is designed for you to customise
  * You can define a custom storage backend to send cached results wherever you want, like cloud storage
  * And while it defaults to saving results with Python's built-in object pickling system,
  * ...you can define a custom cache type to change the format
  * For example, you might want to save tabular results as CSVs or another tabular file type

</aside>

            </textarea>
          </section>

        </section>

        <section>

          <section data-markdown>
            <textarea data-template>
## How does labtech compare to other tools?

<aside class="notes">

  * Right, now we've seen what labtech can do
  * ...how does this compare to other tools out there?

</aside>

            </textarea>
          </section>

          <style>
           .venn {
               position: relative;
           }
           .venn-content {
               position: absolute;
               width: 280px;
               height: 350px;
               top: 100px;
               font-size: 0.5em;
               display: flex;
               align-items: center;
           }
           .venn-content h4 {
               font-size: 1.6em;
           }
           .venn-content p {
               margin-top: 0;
           }
          </style>
          <section data-markdown>
            <textarea data-template>

<div class="venn">

<div class="r-stack">
  <img src="images/venn-1.svg" style="margin: 0 auto;">
  <img src="images/venn-2.svg" style="margin: 0 auto;">
  <img src="images/venn-3.svg" style="margin: 0 auto;" class="fragment" data-fragment-index="5">
</div>

<div class="venn-content" style="left: 105px;">
<div class="venn-content-inner">

  <h4>Concurrency</h4>

  <p class="fragment" data-fragment-index="1"><strong>Local:</strong> <code>multiprocessing</code>, <code>concurrent.futures</code></p>
  <!-- Also: https://github.com/simoninireland/epyc -->

  <p class="fragment" data-fragment-index="2"><strong>Distributed:</strong> Ray Core, Dask.distributed</p>
  <!-- Also: https://ipyparallel.readthedocs.io/en/latest/tutorial/task.html -->

  <p class="fragment" data-fragment-index="3"><strong>Within-task:</strong> Ray Data, Dask.dataframe, <code>sklearn</code></p>

</div>
</div>

<div class="venn-content" style="right: 100px;">
<div class="venn-content-inner">

  <h4>Tracking</h4>

  <div class="fragment" data-fragment-index="4">

  <strong>Saving and visualising: config, results, and outputs</strong>

  MLflow, ClearML, Aim, Weights & Biases (W&B), etc.

  Labtech works with these (MLflow out-of-the-box)

  </div>

</div>
</div>

<div class="venn-content fragment" data-fragment-index="5" style="width: 155px; height: 100px; top: 220px; left: 400px; display: flex; align-items: center;">

  <h4 style="font-size: 1.05em;">Experiment Management</h4>

</div>

</div>

<aside class="notes">

  * Two kinds of tools that can similarly help run experiments: tools for concurrency and tools for tracking experiments
  * Python has lots of tools for concurrency:
    * On your local machine: concurrent futures in the Python standard library makes it easy to run a function many times across multiple processes
    * Ray and Dask can similarly let you run a function across many machines
    * And some data processing libraries have built-in support for distributing parts of a task across processes or machines,
    * ...these in particular actually play quite nicely in conjunction with the tools above or with labtech
  * There are also many tools for tracking and visualising experiments
    * These are more focussed on capturing the results than they are about preparing the experiments
    * Labtech can also play nicely with these specialised tracking tools, and has built-in support for logging experiment parameters and metrics to mlflow
  * However, none of these provide a complete solution for managing experiments
  * I'd class labtech as an *Experiment Management* tool that supports both concurrency and experiment tracking

</aside>

            </textarea>
          </section>

          <style>
           .reveal table.tool-table td,
           .reveal table.tool-table th {
               text-align: center;
           }
           .reveal table.tool-table td:first-child,
           .reveal table.tool-table th:first-child {
               text-align: left;
           }
           .positive {
               color: #7cb342;
               border-color: white !important;
           }
           .negative {
               color: #B34242;
               border-color: white !important;
           }
           .neutral {
               color: #E0931F;
               border-color: white !important;
           }
          </style>
          <section data-markdown>
            <textarea data-template>
### Experiment Management

<table class="tool-table" style="font-size: 0.67em;">
  <thead>
    <th></th>
    <th>Concurrency</th>
    <th>Dependencies</th>
    <th>Caching</th>
    <th class="fragment" data-fragment-index="1">Lightweight</th>
  </thead>
  <tbody>
    <!-- Dagster: Pipelines and caching, but not experiments as it doesn't support permutations -->
    <!--
    <tr>
      <td>Guild AI</td>
      <td>✅</td>
      <td>[✅](https://my.guild.ai/t/pipelines/163)</td>
      <td>[⚠](https://my.guild.ai/t/can-guild-take-advantage-of-cached-results/682)</td>
      <td class="neutral fragment" data-fragment-index="1">YAML + CLI</td>
    </tr>
    -->
    <tr>
      <td>W&B Launch</td>
      <td>✅</td>
      <td>❌</td>
      <td>❌</td> <!-- https://docs.wandb.ai/guides/launch/launch-faqs#when-using-docker-queues-to-run-multiple-jobs-that-download-the-same-artifact-withuse_artifact-do-we-re-download-the-artifact-for-every-single-run-of-the-job-or-is-there-any-caching-going-on-under-the-hood -->      <td class="negative fragment" data-fragment-index="1">CLI + Server</td>
    </tr>
    <!--
    <tr>
      <td>MLflow Pipelines</td>
      <td>✅</td>
      <td class="neutral">⚠</td> No DAG: https://www.mlflow.org/docs/1.30.1/pipelines.html
      <td>❌</td> https://www.mlflow.org/docs/1.30.1/pipelines.html
      <td class="negative fragment" data-fragment-index="1">YAML + Template</td>
    </tr>
    -->
    <tr>
      <td>Polyaxon</td>
      <td>✅</td>
      <td>✅</td> <!-- https://polyaxon.com/docs/intro/automation/automation-dag -->
      <td>✅</td> <!-- https://polyaxon.com/docs/core/scheduling-strategies/operations-caching -->
      <td class="negative fragment" data-fragment-index="1">YAML + Server</td>
    </tr>
    <tr>
      <td>DVC</td> <!-- Does support concurrency with -j: https://dvc.org/doc/command-reference/exp/run -->
      <td>✅</td>
      <td>✅</td> <!-- https://dvc.org/doc/start/data-pipelines/data-pipelines -->
      <td>✅</td> <!-- https://dvc.org/doc/start/data-pipelines/data-pipelines -->
      <td class="neutral fragment" data-fragment-index="1">YAML + CLI</td>
    </tr>
    <tr>
      <td>Ploomber</td>
      <td>✅</td>
      <td>✅</td> <!-- https://docs.ploomber.io/en/latest/user-guide/parametrized.html -->
      <td>✅</td> <!-- https://docs.ploomber.io/en/latest/get-started/intro-to-ploomber.html -->
      <td class="neutral fragment" data-fragment-index="1">YAML + CLI</td>
    </tr>
    <tr>
      <td>joblib</td>
      <td>✅</td>
      <td>❌</td> <!-- Parallel, but no DAG: https://joblib.readthedocs.io/en/stable/why.html -->
      <td>✅</td> <!-- https://joblib.readthedocs.io/en/stable/memory.html -->
      <td class="positive fragment" data-fragment-index="1">Python</td>
    </tr>
    <tr class="highlight">
      <td>labtech</td>
      <td>✅</td>
      <td>✅</td>
      <td>✅</td>
      <td class="positive fragment" data-fragment-index="1">Python</td>
    </tr>
  </tbody>
</table>

<aside class="notes">

  * There are quite a few other experiment management tools out there,
    ...I've tried to represent all the major ones here
  * From my review of these tools, most have good support for the three speed-ups we achieved with labtech earlier
  * However, a big differentiator to me is how lightweight they are to use
  * A lot of these tools require you to define a pipeline of experiment steps in a YAML configuration file
    * ...and some even require you to set up a server
  * By letting you manage your experiments directly from Python code,
    * ...I'd argue that labtech is not just simpler to get up and running with
    * ...but that it gives you more flexibility to have dynamic experiments
    * ...like pipelines with optional steps
  * I could definitely imagine using a tool like Ploomber or DVC
    * ...for more serious experiment management across a team
    * ...or running a regularly scheduled data pipeline,
    * ...but I'd prefer labtech for dynamic and interactive experimentation.
  * It's also worth mentioning that a lot of these tools are very focussed on ML use cases,
    * ...while labtech tries to be more of a general purpose tool

</aside>

            </textarea>
          </section>

        </section>


        <section data-markdown>
          <textarea data-template>
## Labtech Roadmap

* <!-- .element class="fragment" --> Improved memory sharing between tasks
* <!-- .element class="fragment" --> Concurrency backends:
  * Distributed concurrency (Ray or Dask)
  * Multi-interpreter (Python 3.13?)
  * Custom concurrency backends
* <!-- .element class="fragment" --> <span class="highlight">Help users experiment faster</span>

<aside class="notes">

  * Looking ahead, there's a few things I'd like to add into labtech
  * Improved memory sharing, especially looking at what's possible beyond Linux
  * More options for concurrency:
    * Distributing across many machines, probably leveraging Ray or Dask
    * Maybe multi-interpreter concurrency when that gets better support in Python
    * And making it possible to define your own concurrency backends
  * Overall, the goal is to help users experiment faster, so let me know what would most help you

</aside>

          </textarea>
        </section>

        <section data-markdown>
          <textarea data-template>
## Thanks for Listening! <!-- .element style="margin: 0;" -->

<img src="images/fifo-try-labtech.svg" style="margin: 0;">

<div style="font-size: 0.85em;">
  <div><code>pip install labtech</code></div>
  <div><a style="color: white;" href="https://ben-denham.github.io/labtech">ben-denham.github.io/labtech</a></div>
  <div style="margin-top: 20px;" class="fragment">
    <h3 class="highlight">I'd love to hear your feedback!</h3>
    <ul>
      <li>Does labtech fit how you work?</li>
      <li>What would make it fit?</li>
    </ul>
  </div>
</div>

</div>

<aside class="notes">

  * So thanks very much for listening
  * If you've liked what you've seen, go give labtech a go, or give it a star on GitHub
  * And I'd love to hear your feedback, so come talk to me in one of the breaks
  * So thanks again, and I'd be happy to take any questions

</aside>

          </textarea>
        </section>

<!--
        <section data-markdown>
          <textarea data-template>
          </textarea>
        </section>
-->

      </div>
    </div>

    <script src="vendor/jquery-3.7.1.min.js"></script>
    <script src="dist/reveal.js"></script>
    <script src="plugin/notes/notes.js"></script>
    <script src="plugin/markdown/markdown.js"></script>
    <script src="plugin/highlight/highlight.js"></script>
    <script>
     // More info about initialization & config:
     // - https://revealjs.com/initialization/
     // - https://revealjs.com/config/
     Reveal.initialize({
       hash: true,
       /* controls: false, */

       // Learn about plugins: https://revealjs.com/plugins/
       plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ]
     });
    </script>

    <script>
     (function($) {

       Reveal.on('ready', function () {

         $('[data-animation-name]').each(function(idx) {
           const animationName = $(this).data('animation-name');
           const className = `animation-${idx}`;
           $(this).addClass(className);
           const sheet = window.document.styleSheets[0];
           const style = `<style>.${className}.visible { animation-name: ${animationName}; }</style>`
           $('html > head').append(style);
         });

         /* See: https://github.com/hakimel/reveal.js/issues/1289 */
         // utility function that excepts a fragmentshown or fragmenthidden event and returns a boolean indicating whether or not
         // the fragment is a video
         const isVideoFragment = (event) => event.fragment.nodeName === 'VIDEO';

         // Listens for the 'fragmentshown' event; if the fragment being shown is a video, play the video
         Reveal.addEventListener('fragmentshown', (event) => {
           if (isVideoFragment(event)) {
             event.fragment.play();
           }
         });

         // Listens for the 'fragmenthidden' event; if the fragment being hidden is a video, pause the video
         Reveal.addEventListener('fragmenthidden', (event) => {
           if (isVideoFragment(event)) {
             event.fragment.pause();
           }
         });

       });
     })(jQuery);
    </script>

  </body>
</html>
